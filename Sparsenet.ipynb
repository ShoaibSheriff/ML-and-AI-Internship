{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sparsenet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ES1PVRpWh0ej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Sparsenet \n",
        "\n",
        "It stands for *Sparsely Aggregated Convolutional Networks*. It is a network architecture that can be utilised in DenseNets and ResNets to make training faster by significantly reducing the number of parameteres.  These improvements are acheived while maintaining similar levels of accuracy.\n",
        "\n",
        "Check out the original publication at [Sparsely Connected Convolutional Networks](https://arxiv.org/abs/1801.05895).\n",
        "The original repository is hosted at [SparseNet](https://github.com/Lyken17/SparseNet).\n",
        "\n",
        "##Background\n",
        "\n",
        "Convolution nueral networks have become quite important in Computer Vision.  They have been utilised in a wide variery of tasks like Image classification, detetcion and segmenetation. At this time, the most popular ones are : AlexNet, VGG, Inception, ResNet and DenseNet. \n",
        " \n",
        "* __DenseNet__ - It is a network architecture which has the following components - Initial convolution layer, multiple Dense blocks each followed by a Transition block and a final output block. \n",
        "![DenseNet basic](https://cloud.githubusercontent.com/assets/8370623/17981496/fa648b32-6ad1-11e6-9625-02fdd72fdcd3.jpg)The above picture shows an example of a Denset used for classification. The transition block consists of a Convolution and a Pooling layer. The output block consists of a Pooling and a linear(fully connected) layer. <br><br>\n",
        "The actual genius of the densenet lies within the dense blocks. Each dense block consists of multiple dense layers. Each dense layer consists of a batch normalization, ReLU and a Convolution layer. For now, it is easier to treat each dense layer as a single unit. <br><br>Instead of being connected sequentially, the dense layers are conencted in a feed-forward fashion. Basically, for each layer, the outputs of all preceding layers are treated as inputs. Its own feature maps are then, passed on as inputs to all subsequent layers. <br><br>\n",
        "![DenseNet block](https://cloud.githubusercontent.com/assets/8370623/17981494/f838717a-6ad1-11e6-9391-f0906c80bc1d.jpg) <br><br>In the above picture, H1, H2, H3 and H4 are single dense layers. X1, X2, X3 and X4 are outputs of H1, H2, H3 and H4 respectively. Note that, H1 has single input. However, H2 has 2, H3 has 3 and so on. Since Keras allows a layer to have one single input, we need a mechanism to combine mutliple inputs(when applicable). Densenet, uses the mathematical operation **Concatenation** for this pupose. \n",
        "<br>\n",
        "###Concatenation example<br>\n",
        "a = np.array([[1, 2], [3, 4]])<br>\n",
        "b = np.array([[5, 6]])<br><br>\n",
        "np.concatenate((a, b), axis=0) --> Concatenate along row<br>\n",
        "**answer** : ([[1, 2], [3, 4], [5, 6]])<br><br> \n",
        "np.concatenate((a, b.T), axis=1) --> Concatenate along column<br>\n",
        "**answer** : ([[1, 2, 5], [3, 4, 6]])<br><br>\n",
        "You can find more information [here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html).<br>\n",
        "###L and k<br>\n",
        "DenseNets are charecterized by their values of 2 constants - L and k. L is the number of layers and k is the growth rate.<br><br>\n",
        "L is the total number of convolution layers throughout the whole densenet. <br>For example, if there are 3 dense blocks and each dense block has 12 filters. L = 1(initial conv) + 12(first dense block) + 1(1st transition) + 12(second dense block) + 1(2nd transition) + 12(third dense block) + 1(output block) = 40.<br><br>\n",
        "k is called the growth rate. It represents the number of output filters of each dense layer inside a dense block. On careful examination, it can be noticed that, it is also the rate at which the tensor grows inside a dense block. For example, assume input to dense block has 24 filters and k = 12. Then, <br><br> Input to 1st layer = 24 filters. <br> Input to 2nd layer = Output of first layer + Original input = 12 + 24 = 36 filters.<br>Input to 3rd layer = Output of 2nd layer + Output of 1st layer + Original input = 12 + 12 + 24 = 48 filter.<br> and so on.. <br><br>\n",
        "In conclusion, a DenseNet-40-12 represents a Denset with 40 layers and growth rate 12.<br><br>\n",
        "\n",
        "* __ResNet__ - It has an architecture similar to DenseNet. However, the mathematical operation used to combine multiple inputs is **summation followed by a ReLu layer**.\n",
        "\n",
        "##Problems with dense architecture\n",
        "Dense feature aggregation, described above, comes with several potential drawbacks.\n",
        "\n",
        "* In Densenets,  usage of concatenations means that the number of\n",
        "skip connections and parameters grow at the asymptotic rate of O(N2)\n",
        "where N is the network depth. This asymptotically quadratic growth means\n",
        "that a significant portion of the network is devoted to processing previously seen\n",
        "feature representations. Each layer contributes only a few new outputs. Hence, efficiency is low.\n",
        "\n",
        "* In Resnets, after summation operation, it is impossible to seperate individual components of a set of\n",
        "features. As the depth of a residual network grows, the\n",
        "number of features maps aggregated grows linearly. Later features may corrupt\n",
        "or wash-out of the information carried by earlier feature maps.\n",
        "\n",
        "##Sparsenet architecture\n",
        "\n",
        "Sparsenet tries to solve the problems faced by dense aggregations with an architectural change. Here, within a dense block, instead of utilizing outputs of all earlier layers as input, only some selective layers outputs are chosen. <br><br>For layer(x), the inputs are : layer_(x - a^(0)),  layer_(x - a^(1)),  layer_(x - a^(2)) and so on , where a is an integer, most commonly, 2<br><br>\n",
        "\n",
        "![Differences](https://github.com/Lyken17/SparseNet/raw/master/images/dense_and_sparse.png)<br>\n",
        "For example, in a Sparsenet dense block, layer(5) has inputs from: <br>\n",
        "layer(5 -2^0), layer(5 - 2^1) and  layer(5-2^2) => layer(4), layer(3) and layer(1).<br>\n",
        "\n",
        "For a network of total depth N, ResNet and\n",
        "DenseNet have N incoming links per layer, for a total of O(N * N) connections. In contrast, sparse aggregation has only log\n",
        "(N) incoming links per layer, for a total of O(N log(N)) connections.\n",
        "\n",
        "##Advantages\n",
        "Sparsenet offers two main advantages over DenseNets and ResNets - Faster training and more efficient paramter utilization.\n",
        "1. __Fewer parameters__ - Sparsenet offers results similar to DenseNet and ResNet, while using significantly lower number of paramters.<br><br>\n",
        "![Results](https://i.imgur.com/neA484j.png)<br><br>\n",
        "\n",
        "For example, DenseNet-40-12 needs 1.1 million parameters to acheive top 5 accuracy of approximately around 24 on CIFAR 100 data. However, Sparsenet-40-12 acheives the same top 5 score with only 0.76 million parameters.<br>\n",
        "\n",
        "2. __Effecient skip connection utilization__ - \n",
        "![Parameter weights](https://github.com/Lyken17/SparseNet/raw/master/images/cropped_two-weights-int.jpg)<br><br>The above figure shows the average absolute filter weights of convolutional layers in a trained DenseNet and SparseNet. <br><br>For a target layer x and source layer y, a bluish color indicates that, even though a connection exists from the output of y to the input of x, this connection is almost unutilized and is ignored. This means that the network is performing extra work while geting back very little value. A reddish brown color, however, shows that the skip connection is utilized well and adds value.<br><br>\n",
        "In the figure, the Dense Block has a lot of bluish region. This proves that many skip connections are redundant. In Sparsenets though, almost no bluish region can be found. Hence, its clear that no redundant skip connections exist. Each existant skip connection plays a significant role in acheiving the result. <br><br>\n",
        "3.__Effeciency/Flops__ -\n",
        "Flops is a common metric used to represent the work performed at each layer of the network. It stands for the number of __FL__oating point __OP__eration__S__ . Lets understand it with an example. \n",
        "<br>![](https://i.imgur.com/9Q4fl9D.png)<br>Assume a densely connected layer l2 with n2 neurons. Let number of neurons in earlier layer l1 be n1.  Each neuron in l2 is connected to evey neuron in l1. Hence, the weight matrix at layer l2 is of dimneison n2xn1. Since every neuron has single output, output of l1 is of size l1x1.  <br><br> The densely connected layer multiplies weight matrix to l1 output. ie <br> [n2xn1]  \\*  [n1x1]. n2 rows of matrix1 are multiplied to the single column in matrix2 individually. Hence,  total number of operations = n2 * (multiplications in each step + additions in each step). <br></br>Each row multiplies n1 to n1 elements and adds the product. Hence, n1 multiplications and n1-1 additions. So, total number of operations = n2 * (2n1 + 1).<br><br>\n",
        "A RELU unit is then applied, which involves a comparison and a multiply. Since, there are n2 neurons, total operations = 2 * n2.<br></br>\n",
        "Adding total operations, n2 * (2n1 + 1) + n2 * 2 = n2 (2n1 + 1 + 2) = n2 (2n1 + 3) is the total operations at l2 layer.<br></br>\n",
        "![](https://i.imgur.com/nyfWh5E.png) <br></br>\n",
        "The above figure shows a comparison of flops between Sparsenet, Densenet and ResNet. It can be inferred that Sparsenet uses lesser flops compared to the other 2. For instance, DenseNet-121-32 consumes 5.7G, but SparseNet-121-32  only uses 3.46G operations.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0K1T9Ke12ueS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "import keras as keras\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers.pooling import AveragePooling2D, MaxPooling2D\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.utils.layer_utils import convert_all_kernels_in_model, convert_dense_weights_data_format\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RjiJ2RuL2u-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A single dense layer. \n",
        "def _dense_layer(ip, nb_filter, bottleneck=False, dropout_rate=None, weight_decay=1e-4):\n",
        "    ''' Args:\n",
        "        ip: Input keras tensor\n",
        "        nb_filter: number of filters/ growth rate\n",
        "        bottleneck:  conditon to add bottleneck block\n",
        "        dropout_rate: dropout rate\n",
        "        weight_decay: weight decay factor  '''\n",
        "    \n",
        "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    with K.name_scope('conv_block'):\n",
        "        x = BatchNormalization(axis=concat_axis, momentum=0.1, epsilon=1e-5)(ip)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        # If we need a convolution block with a bottleneck \n",
        "        if bottleneck:\n",
        "            inter_channel = nb_filter * 4  \n",
        "\n",
        "            x = Conv2D(inter_channel, (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n",
        "                       kernel_regularizer=l2(weight_decay))(x)\n",
        "            x = BatchNormalization(axis=concat_axis, epsilon=1e-5, momentum=0.1)(x)\n",
        "            x = Activation('relu')(x)\n",
        "\n",
        "        x = Conv2D(nb_filter, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n",
        "        if dropout_rate:\n",
        "            x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qF0AcJj2vSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A utility function that takes a list of all previous inputs (0,1, ..., x -1).\n",
        "# Returns list containing only selective inputs(x-1, x-2, x-4...) as defined by sparsenet architecture.\n",
        "def _exponential_fetch(x_list):\n",
        "    count = len(x_list)\n",
        "    i = 1\n",
        "    inputs = []\n",
        "    while i <= count:\n",
        "        inputs.append(x_list[count - i])\n",
        "        i *= 2\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oaaUOCQ52vbF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A single denseblock. Each layer output is used as input for a select number of future layers.\n",
        "def _dense_block(x, nb_layers, growth_rate, bottleneck=False, dropout_rate=None, weight_decay=1e-4):\n",
        "    ''' Args:\n",
        "        x: input tensor\n",
        "        nb_layers: the number of dense layers inside this dense block\n",
        "        growth_rate: growth rate\n",
        "        bottleneck: coondition to add bottleneck block\n",
        "        dropout_rate: dropout rate\n",
        "        weight_decay: weight decay factor\n",
        "    Returns: keras tensor with nb_layers of conv_block appended\n",
        "    '''\n",
        "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    x_list = [x]\n",
        "\n",
        "    for i in range(nb_layers):\n",
        "        x = _dense_layer(x, growth_rate, bottleneck, dropout_rate, weight_decay)\n",
        "        x_list.append(x)\n",
        "\n",
        "        fetch_outputs = _exponential_fetch(x_list)\n",
        "        x = concatenate(fetch_outputs, axis=concat_axis)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajDTkNpC2vI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A single transition block\n",
        "def _transition_block(ip, nb_filter, compression=1.0, weight_decay=1e-4):\n",
        "    ''' Args:\n",
        "        ip: keras tensor\n",
        "        nb_filter: number of filters\n",
        "        compression: calculated as 1 - reduction. Reduces the number of feature maps\n",
        "                    in the transition block.\n",
        "        dropout_rate: dropout rate\n",
        "        weight_decay: weight decay factor '''\n",
        "    \n",
        "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    with K.name_scope('transition_block'):\n",
        "        x = BatchNormalization(axis=concat_axis, epsilon=1e-5, momentum=0.1)(ip)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n",
        "                   kernel_regularizer=l2(weight_decay))(x)\n",
        "        x = AveragePooling2D((2, 2), strides= 2)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXc0tAk-3ga1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A Sparsenet\n",
        "def _create_SparseNet(img_height, img_width, channel, depth=40, nb_dense_block=3, growth_rate=12,\n",
        "              bottleneck=False, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4,\n",
        "                      nb_classes=10, activation='softmax'):\n",
        "    ''' Arguments\n",
        "            img_height = Input height\n",
        "            img_width = Input width\n",
        "            channel = Number of channels in input\n",
        "            depth: Total number or dense layers in the DenseNet across all dense blocks.\n",
        "            nb_dense_block: number of dense blocks (generally = 3)\n",
        "            growth_rate: number of filters to add per dense layer. Can be\n",
        "                a single integer number. Use a list of numbers if different numbers have\n",
        "                to be used for each layer.\n",
        "            bottleneck: flag to add bottleneck blocks in dense layer\n",
        "            reduction: reduction factor of transition blocks.\n",
        "                Note : reduction value is inverted to compute compression.\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay rate\n",
        "            nb_classes: Number of classes to classify images into.\n",
        "            activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n",
        "                Note that if sigmoid is used, classes must be 1.\n",
        "    # Returns  A Keras model instance. '''\n",
        "    \n",
        "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    if activation not in ['softmax', 'sigmoid']:\n",
        "        raise ValueError('activation must be one of \"softmax\" or \"sigmoid\"')\n",
        "\n",
        "    if activation == 'sigmoid' and classes != 1:\n",
        "        raise ValueError('sigmoid activation can only be used when classes = 1')\n",
        "\n",
        " \n",
        "    if reduction != 0.0:\n",
        "      assert reduction <= 1.0 and reduction > 0.0, 'reduction value must lie between 0.0 and 1.0'\n",
        "    \n",
        "  \n",
        "    # Create a list of items. Each item i represents the number of dense layers in ith dense block.   \n",
        "    count = int((depth - 4) / 3)\n",
        "    # Since a dense layer with bottleneck has twice as many convolution layers, divide the number by 2 when using bottlenecks.\n",
        "    if bottleneck:\n",
        "        count = count // 2\n",
        "    nb_layers = [count for _ in range(nb_dense_block)]\n",
        "            \n",
        "    \n",
        "    # Create a list of items. Each item i represents growth rate in ith dense block. \n",
        "    if type(growth_rate) is list or type(growth_rate) is tuple:\n",
        "        growth_rate = list(growth_rate)\n",
        "        assert len(growth_rate) == len(nb_layers)\n",
        "    else:\n",
        "        growth_rate = [growth_rate for _ in range(len(nb_layers))]\n",
        "   \n",
        "\n",
        "    # compute compression factor\n",
        "    compression = 1.0 - reduction\n",
        "\n",
        "    input = Input(shape=(img_height, img_width, channel,))\n",
        "    # Initial convolution\n",
        "    x = Conv2D(2*growth_rate[0], (3, 3), kernel_initializer='he_normal', padding='same',\n",
        "               strides=(1, 1), use_bias=False, kernel_regularizer=l2(weight_decay))(input)\n",
        "\n",
        "\n",
        "     # Add dense blocks. Handle last one seperately since it does not have a transition block\n",
        "    for block_idx in range(nb_dense_block - 1):\n",
        "        x = _dense_block(x, nb_layers[block_idx], growth_rate[block_idx], bottleneck=bottleneck,\n",
        "                                    dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "        # add transition_block\n",
        "        x = _transition_block(x, x.shape[3], compression=compression, weight_decay=weight_decay)\n",
        "\n",
        "    # The last dense_block does not have a transition_block\n",
        "    x = _dense_block(x, nb_layers[-1], growth_rate[-1], bottleneck=bottleneck,\n",
        "                                dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Output block\n",
        "    x = BatchNormalization(axis=concat_axis, epsilon=1e-5, momentum=0.1)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    output = Dense(nb_classes, activation=activation)(x)\n",
        "\n",
        "        \n",
        "    # Create model.\n",
        "    model = Model(inputs=[input], outputs=[output], name='densenet')\n",
        "  \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LOxjgIKxUJZQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "depth = 40\n",
        "nb_dense_block = 3\n",
        "growth_rate = 24\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIR0u2ZaOhsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  \n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yV-95cEwlt7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data Augmentation - Horizontal flip\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4eChMkg3mvxn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data Augmentation - Random Shift. Note : random crop is not supported by Keras\n",
        "shift = 0.2\n",
        "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "22bQ3qwRjsgP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Data Normalization\n",
        "It is a procedure performed as a pre processing step on data.  It is used to standardize the range of independent variables or features of data.<br><br>\n",
        "For example, in image processing classification task, consider two images  of the same object. However, one of the image was shot in low light condition. In such case, the network may fail to recognise them as the same object, since pixel values would be significantly less. Subtracting the mean circumvents this issue and helps to remove network dependence on photo shooting conditions. <br><br>\n",
        "\n",
        "Similarly,  division by the standard deviation mitigates variations in the spread of the data about the mean so that the two images have similar means and standard deviations. <br><br> Lack of similar ranges would mean that a particular step in weights would have different impact on each data.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "b79mGMNKt6xT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data normalization\n",
        "cifar_mean = x_train.mean(axis=(0, 1, 2), keepdims=True)\n",
        "cifar_std = x_train.std(axis=(0, 1, 2), keepdims=True)\n",
        "\n",
        "x_train = (x_train - cifar_mean) / (cifar_std + 1e-8)\n",
        "x_test = (x_test - cifar_mean) / (cifar_std + 1e-8)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6hwANhVB_lw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = _create_SparseNet(img_height, img_width, channel, depth=depth, nb_dense_block=nb_dense_block,\n",
        "                            growth_rate=growth_rate, nb_classes=num_classes)\n",
        "print(\"Model created\")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rf06J79Sp0Eg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Did not get better results with random crop. Hence, unused.\n",
        "def random_crop(images, paddings):\n",
        "  \n",
        "    npad = ((0,0), paddings, paddings, (0, 0))\n",
        "    paddedImages = np.pad(images, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "    print(paddedImages.shape)\n",
        "\n",
        "    height, width = (40,40)\n",
        "    dy, dx = (height - 2*paddings[0], width - 2*paddings[1])\n",
        "    if width < dx or height < dy:\n",
        "        return None\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    return paddedImages[:, y:(y+dy), x:(x+dx)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h861jdFoveRg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "sgd = SGD(lr=0.1, decay=0.0001, momentum=0.9, nesterov=True)\n",
        "\n",
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "filepath=\"models-improvement.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test), callbacks=callbacks_list)\n",
        "\n",
        "from keras.models import load_model\n",
        "model2 = load_model(filepath)\n",
        "\n",
        "# Save the model in to .h5 format\n",
        "model.save('SPNet-100epoch.h5')\n",
        "\n",
        "from google.colab import files\n",
        "#does not work on ubuntu\n",
        "files.download('SPNet-100epoch.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CNyjdK2M_fAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model2 = load_model(filepath)\n",
        "\n",
        "model2.optimizer.lr = model2.optimizer.lr/10\n",
        "print(keras.backend.eval(model2.optimizer.lr))\n",
        "\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model2.fit(x_train, y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxUT2u_8F-7M",
        "colab_type": "code",
        "outputId": "f942292a-2f05-4611-e92e-343f4b98b192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "keras.backend.eval(model2.optimizer.lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "vKWHOIiawJMG",
        "colab_type": "code",
        "outputId": "fae29455-0c0b-4c79-8063-2e9a2d018348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "best_model_total = load_model(filepath)\n",
        "\n",
        "# Test the model\n",
        "score = best_model_total.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Save the trained weights in to .h5 format\n",
        "best_model_total.save_weights(\"SPW.h5\")\n",
        "best_model_total.save(\"SPM.h5\")\n",
        "\n",
        "#print(\"Saved model to disk\")\n",
        "\n",
        "from google.colab import files\n",
        "#does not work on ubuntu\n",
        "files.download('SPW.h5')\n",
        "files.download('SPM.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 20s 2ms/step\n",
            "Test loss: 0.5409464004039765\n",
            "Test accuracy: 0.8902\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}