{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Winograd.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XScg8jXjpEc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "kernel_a = np.random.randint(low = -10, high = 10, size=(3,3));\n",
        "input_a = np.random.randint(low = -10, high = 10, size=(32,32));\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ORdyobPJczqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1547
        },
        "outputId": "a9ac18e7-b2ee-4de4-8cd5-e47542913b02"
      },
      "cell_type": "code",
      "source": [
        "#Normal convolution\n",
        "\n",
        "k = tf.convert_to_tensor(kernel_a, np.float32);\n",
        "i = tf.convert_to_tensor(input_a, np.float32);\n",
        "\n",
        "kernelt = tf.reshape(k, [3, 3, 1, 1], name='kernel')\n",
        "imaget  = tf.reshape(i, [1, 32, 32, 1], name='image')\n",
        "\n",
        "ans_conv_tens = tf.squeeze(tf.nn.conv2d(imaget, kernelt, [1, 1, 1, 1], \"VALID\"))\n",
        "start_time = time.time()\n",
        "\n",
        "# VALID means no padding\n",
        "with tf.Session() as sess:\n",
        "   ans_conv = sess.run(ans_conv_tens)\n",
        "\n",
        "print(ans_conv)\n",
        "exec_time_conv = time.time() - start_time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-142.  -52.   -5.  178. -225.   10.  -58.  181.  110. -143.  -34.  -15.\n",
            "   148.  -90.   32.   28.  -36.  126. -191.  -47.  241. -156.    0.   57.\n",
            "   104.   16. -106.  -89. -108.  -89.]\n",
            " [-248.   80.   94.   99.  -62.    0.  233. -131. -133.  -68.  118.  153.\n",
            "   169.  -67. -129.   52.  -52.  152.   55.  -38.  149. -154.  129.   64.\n",
            "  -167. -120.   58.  -15.  -29.  219.]\n",
            " [  -4.   40. -126.  111.   45.  -78.  -91.   97. -139.   33.  214. -113.\n",
            "  -104.   22.   -9.   15. -169.  128.    8.  -92.  -37.  -41.  124. -144.\n",
            "   179.  129.    4. -185.   10.  157.]\n",
            " [  12. -296.  141.   15.  -72.  -98. -106.  185.  156.  -28. -163.  -59.\n",
            "  -104.   85.  141.  -19.   69. -121.  149. -123.  -81. -176.  224. -168.\n",
            "   157.   21.  -30.   10. -137.   24.]\n",
            " [  21.  -14. -108.  311. -220.  -57.   46.   60.  119.  -39. -120.  282.\n",
            "     1. -170.   56.  -64.    2.   24.   84. -126.  141.  -74.  188. -160.\n",
            "   -38.  -81.   72.   90. -264.  271.]\n",
            " [ 206.   91. -274.  146.  -14.   -7.  -73.   93.  -76.   78.  125.  -52.\n",
            "   -34.    6.   -8.  -24. -189.   66.   59.   -6.  114.  -54.  -27.  -82.\n",
            "   -35.   16. -119.  264.   -3. -175.]\n",
            " [  -6.   32. -163.   36.  -32.   95. -165.  170. -178.  -79.   -7.   45.\n",
            "   -96.   21.  -31.  321.  -85.  -46.  -17.   90. -121.   -9. -144.  -11.\n",
            "    -6.  283. -115.  102.  -76.  124.]\n",
            " [ -42.   93.   -1.  -16.   32.  164. -120. -153.  209.  -55.  105.  202.\n",
            "  -188.   68.   -6.   81.  130.  -73. -218.   84.  -49.  114.   88.  199.\n",
            "  -138.   63.  -14.   16.  -74.    0.]\n",
            " [ 143.   84.  -99.   99.   68.  167.   14.  -10.  248. -126.  -77.   47.\n",
            "     5.   70. -137.  -44.   97.  -44.   87.   81. -155.  134.   74.   72.\n",
            "  -100.  -49.  -49.  -46.   58. -130.]\n",
            " [ -62.   16. -140.   53.  -76.   80.   63. -214.  101. -112.  226.  -12.\n",
            "  -175.  144.  112.  -24. -148.  220.   32.   46. -200.  160. -176.   27.\n",
            "   -46.   52.   32. -175.  104. -173.]\n",
            " [-212.  252.  -50. -177.  -55.  244.   35. -335.   65.  155.    2.   27.\n",
            "    42.   25.  -51.  -77.  -97.    8. -142.  290.   -4.  -22. -205.  128.\n",
            "  -120.   -2.  202. -178.  170.  -72.]\n",
            " [-140.   17. -143.   82. -129.  136.  195.   54. -181.  -82.  -71.  136.\n",
            "   -96. -109.   46.   35.  -14.  135.  -66.  159. -102.  -18.  -93.   -3.\n",
            "    95. -117.   -9.  113.   59.  -40.]\n",
            " [ -27.   16.  -11.  200. -219.   90.  -25.  -20.  -68.   48. -197.   47.\n",
            "    52.   -5.   74.  192.  -86.   90.  103. -107.  -13.  224. -110. -119.\n",
            "    30.   25.   15.  -60.  -40.  149.]\n",
            " [ -15. -129.  182.  112. -242.   70. -146.   86.   -6.  201.   15.    9.\n",
            "     2.    0.  -95.   35.   57.   60. -222.   -1.  136.  -90.  159.  -72.\n",
            "  -105.  -95.   26.  174. -165.  -29.]\n",
            " [ -65.  128. -183.   18.  135.  -16.  -93.  224. -173.  175.  -11.  111.\n",
            "   -15.  -66. -153.   71.  -57.  106.  -64.  -22. -209.   21.   68.   16.\n",
            "    10.   -4.  152.  -56. -197.  149.]\n",
            " [ 252. -131.  -33.   85.    3.   46.   -9.  203. -242.  -26.   12. -161.\n",
            "   112.  165. -129.   83. -102.   56.  118. -228.    9.   18.  -63.  -69.\n",
            "   182.   94.    0.  -63.   74.  -37.]\n",
            " [-149.  150.   83. -122.  -91.  225.  -49.  133. -182.  -60.   71. -193.\n",
            "   192.   16.    7.  110.  -44.    9.  106.   51.  107.  -93.   60. -130.\n",
            "   197. -119. -131.   43.  -11.   81.]\n",
            " [  46.   15. -174.  230. -102. -245.  -29.  -35. -119.   69.  295. -102.\n",
            "    -8.   25.  155. -177.   68.  -29.  -58. -106.  145.  -27.   25. -134.\n",
            "   171.   23.  -65. -100.  -11.   68.]\n",
            " [ -50.   53.  -96.  168. -112.  -21.  121.  162.   24.  -89.  165. -283.\n",
            "   194.   -3.  -47. -159.  128.   -7. -109.   52.  103. -113.  119.  -43.\n",
            "   -34.   37.   30.   68. -126.  143.]\n",
            " [ 183.  242. -212. -101.   -6.  183. -117.   88. -143.  -12.   45.  -99.\n",
            "    -2.  -18.   36.  -51.   39.  211.  -11. -253.  -24.  -82.   69.  -91.\n",
            "   -39.   89.  180.   68.  -11. -104.]\n",
            " [ -19.  -88.   48.   33. -150.  -32.   64.  123.  -91.  170.  -58. -130.\n",
            "    -7.   58.   96.   44. -187.   74.  -18. -231.  221.    6.  -34.   90.\n",
            "   -37.  221.  -97.  151.  -56.  -28.]\n",
            " [-156.  138.   -2.   66.  -16.   99.  -60.  -40. -139.  107.  -83.  178.\n",
            "  -230.   11.  -59.  -63.  152.    7.  319. -115.  167.  -60. -155.  111.\n",
            "    93. -148.  -45.  -64.  -84.  156.]\n",
            " [ -64.   -7.   47.   69.  -25.   -7. -104.  125.  -81.   84.  -32.   96.\n",
            "   117.  142.  -12.  -22. -135. -105.   68.  -61.   69.  172.   44. -134.\n",
            "  -111.  151.   32.  -83.  -28.   60.]\n",
            " [  78. -132.  113.    5. -155.  -21.  223.   28. -322.  136.   18.    2.\n",
            "  -165.  273.  122.  -59.  -33. -178.  -19.  104. -114.   79. -145. -119.\n",
            "   182.  -36.  104. -164. -178.  149.]\n",
            " [   8. -210.   40.  265. -128. -139.   26.   40.   48. -223.  123.   67.\n",
            "  -304.  115. -123.  136. -159.    8.   80.  162.  -71.  -87.   20.  216.\n",
            "   -60.  -28.  -25.  130.  103. -212.]\n",
            " [  13.   53. -199.  -89.   96. -155.  -97.  164.  115. -165.  113.  106.\n",
            "  -155.  -47.  -13. -118.  180.  -15. -146.   69.  -38. -102.  107.  106.\n",
            "  -176.   27. -199.  371.  -36. -171.]\n",
            " [ -14.   57.   58.  -85.   10.   42.  -43.   64.  -33. -102.   70.   90.\n",
            "  -119. -208.   34.  216.  -18.  -47.  -33.  105.  292.   90. -165.   13.\n",
            "  -134.  352. -154.    4.   -8.  102.]\n",
            " [ -53. -126.  202.   93.  -99.   87.  -10. -118.  -58.   76.   13.   14.\n",
            "   229. -116.   77.   -2.  -65.  125.   20.  132.  -13. -153. -169.  242.\n",
            "  -281.  231. -184. -101.  -75.  -14.]\n",
            " [  55. -307.  122.  143. -143.   42.   54.   44.  -13.  -53.   74. -121.\n",
            "    72.   -2.  -68.  -16.  197.  -84.  -77.  -73.  -45.   31.   82.   99.\n",
            "  -126.   75. -164.  189.   10.  -65.]\n",
            " [  47.  160.  -74.  -27.  -88.  -99.   80.   55.  216. -180.   94. -163.\n",
            "  -101.   19.  141.   21.   -4. -223.  -68.   26.   92.  173.   16.   57.\n",
            "    55.  -80. -179.  132. -138.   41.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EwEcmUYEf43u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.lib.stride_tricks import as_strided as ast\n",
        "\n",
        "def norm_shape(shape):\n",
        "    '''\n",
        "    Normalize numpy array shapes so they're always expressed as a tuple,\n",
        "    even for one-dimensional shapes.\n",
        "     \n",
        "    Parameters\n",
        "        shape - an int, or a tuple of ints\n",
        "     \n",
        "    Returns\n",
        "        a shape tuple\n",
        "    '''\n",
        "    try:\n",
        "        i = int(shape)\n",
        "        return (i,)\n",
        "    except TypeError:\n",
        "        # shape was not a number\n",
        "        pass\n",
        " \n",
        "    try:\n",
        "        t = tuple(shape)\n",
        "        return t\n",
        "    except TypeError:\n",
        "        # shape was not iterable\n",
        "        pass\n",
        "     \n",
        "    raise TypeError('shape must be an int, or a tuple of ints')\n",
        "  \n",
        "def _create_tiles(a,ws,ss = None,flatten = False):\n",
        "    '''\n",
        "    Return a sliding window over a in any number of dimensions\n",
        "     \n",
        "    Parameters:\n",
        "        a  - an n-dimensional numpy array\n",
        "        ws - an int (a is 1D) or tuple (a is 2D or greater) representing the size\n",
        "             of each dimension of the window\n",
        "        ss - an int (a is 1D) or tuple (a is 2D or greater) representing the\n",
        "             amount to slide the window in each dimension. If not specified, it\n",
        "             defaults to ws.\n",
        "        flatten - if True, all slices are flattened, otherwise, there is an\n",
        "                  extra dimension for each dimension of the input.\n",
        "     \n",
        "    Returns\n",
        "        an array containing each n-dimensional window from a\n",
        "    '''\n",
        "     \n",
        "    if None is ss:\n",
        "        # ss was not provided. the windows will not overlap in any direction.\n",
        "        ss = ws\n",
        "    ws = norm_shape(ws)\n",
        "    ss = norm_shape(ss)\n",
        "     \n",
        "    # convert ws, ss, and a.shape to numpy arrays so that we can do math in every\n",
        "    # dimension at once.\n",
        "    ws = np.array(ws)\n",
        "    ss = np.array(ss)\n",
        "    shape = np.array(a.shape)\n",
        "     \n",
        "     \n",
        "    # ensure that ws, ss, and a.shape all have the same number of dimensions\n",
        "    ls = [len(shape),len(ws),len(ss)]\n",
        "    if 1 != len(set(ls)):\n",
        "        raise ValueError(\\\n",
        "        'a.shape, ws and ss must all have the same length. They were %s' % str(ls))\n",
        "     \n",
        "    # ensure that ws is smaller than a in every dimension\n",
        "    if np.any(ws > shape):\n",
        "        raise ValueError(\\\n",
        "        'ws cannot be larger than a in any dimension.\\\n",
        " a.shape was %s and ws was %s' % (str(a.shape),str(ws)))\n",
        "     \n",
        "    # how many slices will there be in each dimension?\n",
        "    newshape = norm_shape(((shape - ws) // ss) + 1)\n",
        "    # the shape of the strided array will be the number of slices in each dimension\n",
        "    # plus the shape of the window (tuple addition)\n",
        "    newshape += norm_shape(ws)\n",
        "    # the strides tuple will be the array's strides multiplied by step size, plus\n",
        "    # the array's strides (tuple addition)\n",
        "    newstrides = norm_shape(np.array(a.strides) * ss) + a.strides\n",
        "    strided = ast(a,shape = newshape,strides = newstrides)\n",
        "    if not flatten:\n",
        "        return strided\n",
        "     \n",
        "    # Collapse strided so that it has one more dimension than the window.  I.e.,\n",
        "    # the new array is a flat list of slices.\n",
        "    meat = len(ws) if ws.shape else 0\n",
        "    firstdim = (np.product(newshape[:-meat]),) if ws.shape else ()\n",
        "    dim = firstdim + (newshape[-meat:])\n",
        "    # remove any dimensions with size 1\n",
        "    dim = filter(lambda i : i != 1,dim)\n",
        "    return strided.reshape(dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTnrLu5y5KI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Winograd - prereq\n",
        "# Using F(2x2, 3x3)\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Block size is m+r-1 = 2+3-1 = 4, stride length = r-1 = 2;\n",
        "tilesA = _create_tiles(a = input_a, ws = (4, 4), ss = (2,2)) #returns (15x15 array of tiles)\n",
        "tilesB = tilesA.reshape(1,15*15,4,4); #flatten array\n",
        "tiles = tilesB[0];\n",
        "\n",
        "# defined in the paper\n",
        "G = np.array([[1, 0, 0], [0.5, 0.5, 0.5], [0.5, -0.5, 0.5], [0, 0, 1]])\n",
        "Bt = np.array([[1, 0, -1, 0],[0, 1, 1, 0], [0, -1, 1, 0], [0, 1, 0, -1]])\n",
        "At = np.array(([1, 1, 1, 0], [0, 1, -1, -1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmGN2fvTgJhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1547
        },
        "outputId": "7e3f7698-6db9-4e2f-8a29-5a75d1cd5fa8"
      },
      "cell_type": "code",
      "source": [
        "#Winograd\n",
        "start_time = time.time()\n",
        "\n",
        "lhs = np.dot(np.dot(G, kernel_a), G.T)\n",
        "\n",
        "ans_wino = np.zeros(shape = (30,30))\n",
        "\n",
        "for i1 in range(0,15):\n",
        "  for i2 in range(0,15):\n",
        "    ti = tiles[i1*15 + i2];\n",
        "    rhsi = np.dot(np.dot(Bt,ti), Bt.T)\n",
        "    insidei = lhs * rhsi\n",
        "    ansi = np.dot(np.dot(At, insidei), At.T)\n",
        "    #print(ansi)\n",
        "    ans_wino[2*i1:2*i1+2,2*i2:2*i2+2] += ansi\n",
        "\n",
        "print(ans_wino)\n",
        "exec_time_wino = time.time() - start_time"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-142.  -52.   -5.  178. -225.   10.  -58.  181.  110. -143.  -34.  -15.\n",
            "   148.  -90.   32.   28.  -36.  126. -191.  -47.  241. -156.    0.   57.\n",
            "   104.   16. -106.  -89. -108.  -89.]\n",
            " [-248.   80.   94.   99.  -62.    0.  233. -131. -133.  -68.  118.  153.\n",
            "   169.  -67. -129.   52.  -52.  152.   55.  -38.  149. -154.  129.   64.\n",
            "  -167. -120.   58.  -15.  -29.  219.]\n",
            " [  -4.   40. -126.  111.   45.  -78.  -91.   97. -139.   33.  214. -113.\n",
            "  -104.   22.   -9.   15. -169.  128.    8.  -92.  -37.  -41.  124. -144.\n",
            "   179.  129.    4. -185.   10.  157.]\n",
            " [  12. -296.  141.   15.  -72.  -98. -106.  185.  156.  -28. -163.  -59.\n",
            "  -104.   85.  141.  -19.   69. -121.  149. -123.  -81. -176.  224. -168.\n",
            "   157.   21.  -30.   10. -137.   24.]\n",
            " [  21.  -14. -108.  311. -220.  -57.   46.   60.  119.  -39. -120.  282.\n",
            "     1. -170.   56.  -64.    2.   24.   84. -126.  141.  -74.  188. -160.\n",
            "   -38.  -81.   72.   90. -264.  271.]\n",
            " [ 206.   91. -274.  146.  -14.   -7.  -73.   93.  -76.   78.  125.  -52.\n",
            "   -34.    6.   -8.  -24. -189.   66.   59.   -6.  114.  -54.  -27.  -82.\n",
            "   -35.   16. -119.  264.   -3. -175.]\n",
            " [  -6.   32. -163.   36.  -32.   95. -165.  170. -178.  -79.   -7.   45.\n",
            "   -96.   21.  -31.  321.  -85.  -46.  -17.   90. -121.   -9. -144.  -11.\n",
            "    -6.  283. -115.  102.  -76.  124.]\n",
            " [ -42.   93.   -1.  -16.   32.  164. -120. -153.  209.  -55.  105.  202.\n",
            "  -188.   68.   -6.   81.  130.  -73. -218.   84.  -49.  114.   88.  199.\n",
            "  -138.   63.  -14.   16.  -74.    0.]\n",
            " [ 143.   84.  -99.   99.   68.  167.   14.  -10.  248. -126.  -77.   47.\n",
            "     5.   70. -137.  -44.   97.  -44.   87.   81. -155.  134.   74.   72.\n",
            "  -100.  -49.  -49.  -46.   58. -130.]\n",
            " [ -62.   16. -140.   53.  -76.   80.   63. -214.  101. -112.  226.  -12.\n",
            "  -175.  144.  112.  -24. -148.  220.   32.   46. -200.  160. -176.   27.\n",
            "   -46.   52.   32. -175.  104. -173.]\n",
            " [-212.  252.  -50. -177.  -55.  244.   35. -335.   65.  155.    2.   27.\n",
            "    42.   25.  -51.  -77.  -97.    8. -142.  290.   -4.  -22. -205.  128.\n",
            "  -120.   -2.  202. -178.  170.  -72.]\n",
            " [-140.   17. -143.   82. -129.  136.  195.   54. -181.  -82.  -71.  136.\n",
            "   -96. -109.   46.   35.  -14.  135.  -66.  159. -102.  -18.  -93.   -3.\n",
            "    95. -117.   -9.  113.   59.  -40.]\n",
            " [ -27.   16.  -11.  200. -219.   90.  -25.  -20.  -68.   48. -197.   47.\n",
            "    52.   -5.   74.  192.  -86.   90.  103. -107.  -13.  224. -110. -119.\n",
            "    30.   25.   15.  -60.  -40.  149.]\n",
            " [ -15. -129.  182.  112. -242.   70. -146.   86.   -6.  201.   15.    9.\n",
            "     2.    0.  -95.   35.   57.   60. -222.   -1.  136.  -90.  159.  -72.\n",
            "  -105.  -95.   26.  174. -165.  -29.]\n",
            " [ -65.  128. -183.   18.  135.  -16.  -93.  224. -173.  175.  -11.  111.\n",
            "   -15.  -66. -153.   71.  -57.  106.  -64.  -22. -209.   21.   68.   16.\n",
            "    10.   -4.  152.  -56. -197.  149.]\n",
            " [ 252. -131.  -33.   85.    3.   46.   -9.  203. -242.  -26.   12. -161.\n",
            "   112.  165. -129.   83. -102.   56.  118. -228.    9.   18.  -63.  -69.\n",
            "   182.   94.    0.  -63.   74.  -37.]\n",
            " [-149.  150.   83. -122.  -91.  225.  -49.  133. -182.  -60.   71. -193.\n",
            "   192.   16.    7.  110.  -44.    9.  106.   51.  107.  -93.   60. -130.\n",
            "   197. -119. -131.   43.  -11.   81.]\n",
            " [  46.   15. -174.  230. -102. -245.  -29.  -35. -119.   69.  295. -102.\n",
            "    -8.   25.  155. -177.   68.  -29.  -58. -106.  145.  -27.   25. -134.\n",
            "   171.   23.  -65. -100.  -11.   68.]\n",
            " [ -50.   53.  -96.  168. -112.  -21.  121.  162.   24.  -89.  165. -283.\n",
            "   194.   -3.  -47. -159.  128.   -7. -109.   52.  103. -113.  119.  -43.\n",
            "   -34.   37.   30.   68. -126.  143.]\n",
            " [ 183.  242. -212. -101.   -6.  183. -117.   88. -143.  -12.   45.  -99.\n",
            "    -2.  -18.   36.  -51.   39.  211.  -11. -253.  -24.  -82.   69.  -91.\n",
            "   -39.   89.  180.   68.  -11. -104.]\n",
            " [ -19.  -88.   48.   33. -150.  -32.   64.  123.  -91.  170.  -58. -130.\n",
            "    -7.   58.   96.   44. -187.   74.  -18. -231.  221.    6.  -34.   90.\n",
            "   -37.  221.  -97.  151.  -56.  -28.]\n",
            " [-156.  138.   -2.   66.  -16.   99.  -60.  -40. -139.  107.  -83.  178.\n",
            "  -230.   11.  -59.  -63.  152.    7.  319. -115.  167.  -60. -155.  111.\n",
            "    93. -148.  -45.  -64.  -84.  156.]\n",
            " [ -64.   -7.   47.   69.  -25.   -7. -104.  125.  -81.   84.  -32.   96.\n",
            "   117.  142.  -12.  -22. -135. -105.   68.  -61.   69.  172.   44. -134.\n",
            "  -111.  151.   32.  -83.  -28.   60.]\n",
            " [  78. -132.  113.    5. -155.  -21.  223.   28. -322.  136.   18.    2.\n",
            "  -165.  273.  122.  -59.  -33. -178.  -19.  104. -114.   79. -145. -119.\n",
            "   182.  -36.  104. -164. -178.  149.]\n",
            " [   8. -210.   40.  265. -128. -139.   26.   40.   48. -223.  123.   67.\n",
            "  -304.  115. -123.  136. -159.    8.   80.  162.  -71.  -87.   20.  216.\n",
            "   -60.  -28.  -25.  130.  103. -212.]\n",
            " [  13.   53. -199.  -89.   96. -155.  -97.  164.  115. -165.  113.  106.\n",
            "  -155.  -47.  -13. -118.  180.  -15. -146.   69.  -38. -102.  107.  106.\n",
            "  -176.   27. -199.  371.  -36. -171.]\n",
            " [ -14.   57.   58.  -85.   10.   42.  -43.   64.  -33. -102.   70.   90.\n",
            "  -119. -208.   34.  216.  -18.  -47.  -33.  105.  292.   90. -165.   13.\n",
            "  -134.  352. -154.    4.   -8.  102.]\n",
            " [ -53. -126.  202.   93.  -99.   87.  -10. -118.  -58.   76.   13.   14.\n",
            "   229. -116.   77.   -2.  -65.  125.   20.  132.  -13. -153. -169.  242.\n",
            "  -281.  231. -184. -101.  -75.  -14.]\n",
            " [  55. -307.  122.  143. -143.   42.   54.   44.  -13.  -53.   74. -121.\n",
            "    72.   -2.  -68.  -16.  197.  -84.  -77.  -73.  -45.   31.   82.   99.\n",
            "  -126.   75. -164.  189.   10.  -65.]\n",
            " [  47.  160.  -74.  -27.  -88.  -99.   80.   55.  216. -180.   94. -163.\n",
            "  -101.   19.  141.   21.   -4. -223.  -68.   26.   92.  173.   16.   57.\n",
            "    55.  -80. -179.  132. -138.   41.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-vrysl9xxt7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9c01a9d3-ea83-42ec-e81f-1867035effdd"
      },
      "cell_type": "code",
      "source": [
        "print(\"--- Does winograd answer match with normal convolution ? %s ---\" % np.array_equiv(ans_conv, ans_wino))\n",
        "print(\"--- Time with normal convolution %s ---\" % exec_time_conv)\n",
        "print(\"--- Time with winograd convolution %s ---\" % exec_time_wino)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Does winograd answer match with normal convolution ? True ---\n",
            "--- Time with normal convolution 0.013360261917114258 ---\n",
            "--- Time with winograd convolution 0.022821664810180664 ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}